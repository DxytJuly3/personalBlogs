---
layout: '../../layouts/MarkdownPost.astro'
title: '[Linux] '
pubDate: 2024-01-08
description: ''
author: '七月.cc'
cover:
    url: 'https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401080147048.webp'
    square: 'https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401080147048.webp'
    alt: 'cover'
tags: ["Linux网络", "传输层", "协议", "TCP", "约字 -- 阅读时间≈分钟"]
theme: 'light'
featured: false
---

上一篇文章, 针对`UDP`协议的格式、数据等内容做了一些简单的介绍. 并且提到, 在网络协议栈`TCP/IP`模型的传输层中, 有两个最具代表性的协议: `UDP`和`TCP`

本篇文章就简单介绍一下`TCP`协议

# `TCP`协议

`TCP`协议, 完整的称呼其实叫: **传输控制协议(Transmission Control Protocol)**

从名字就可以看出来, `TCP`协议 实际是可以对数据的传输进行详细控制的

## `TCP`协议格式

使用`TCP`协议进行通信, 操作系统会对数据添加`TCP`的协议报头, 那么`TCP`协议的格式是这样的:

![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/image-20240116205033001.webp)

可以看到, `TCP`协议报头要比`UDP`协议报头复杂的多

在介绍`UDP`协议时提到过, `TCP/IP`协议栈的每一层在进行数据传输时, 都需要考虑三个内容: **封装、解包和分用**

`TCP`协议报头中有两个熟悉的面孔: **16位源端口号 和 16位目的端口号**, 这两个数据的作用就不用多做介绍了, 是为了解决 **分用** 的问题的

### `TCP`协议的封装和解包

`UDP`协议的报头采用了8字节的固定长度, 所以可以很好的解决封装和解包的问题

而在`TCP`报文中, 我们可以看到在前`20字节`之外, 还有一个占有`n字节`的选项. 这`n字节`的部分是不固定的, 并且也属于`TCP`报头的内容

**`TCP`报头没有选项时一共`20字节`, 这20字节的数据是必须的, 被称为标准长度**

`TCP`协议在使用时, 报头的长度可能90%的情况都是标准长度(20字节). 即使选项不是必须的, 也不能忽略那`n字节`的选项长度

也就是说, **`TCP`报头的长度最少为`20字节`, 但是并不固定 可能会更大.**

既然`TCP`报头长度不固定, 那么怎么解决封装和解包的问题呢?

观察`TCP`报文格式可以发现, 在报头的`第13字节(4位空间)`处, 存储的数据表示的是 **首部长度**. 这个**首部长度, 实际就表示`TCP`协议报头的长度**

但是, 又有一个问题: `TCP`报头长度最少`20字节`, 但是报头中表示首部长度的数据只有4位, 最多也就能表示16个数据(0000~1111), 好像不太够用

> 4位空间:
>
> | `0000` | `0001` | `0010` | `0011` |
>| :----: | :----: | :----: | :----: |
> | `0100` | `0101` | `0110` | `0111` |
>| `1000` | `1001` | `1010` | `1011` |
> | `1100` | `1101` | `1110` | `1111` |

实际上是够用的, 因为 **这`4位 16个数据`的单位并不是`1字节`, 而是`4字节`. 那么也就是说, 这四位数据最多可以表示 `60字节`, 即 `TCP`首部长度最大为`60字节`**

但是, 不要忽略一个细节, `TCP`报头的标准长度为`20字节`, 也就是说最少为`20字节`. 那么, 实际上这 **4位表示首部长度的数据** 至少是`0101(5)`

既然`TCP`报头中存储有表示报头长度的数据, 那么就可以很好的解决封装和解包的问题

> 问题:
>
> `TCP`报头并没有表示报文总长度的数据, 那么接收端如何接收到报文中所包含的所有数据呢
>
> 这个问题要等到介绍网络`IP`层才会有一个答案

## `TCP`的可靠性

无论是`UDP/TCP Socket`的介绍, 还是上一篇文章中关于`UDP`协议的介绍, 文章中总提到: `UDP`协议是不可靠的, `TCP`协议是可靠的

那么, 究竟什么是不可靠? 什么是可靠?

什么是不可靠呢?

实际上我们已经提到过什么是不可靠的表现, 比如: 出现丢包、乱序、检验失败等情况, 并且不对这种情况做出处理. 这些情况, 在`UDP`协议中可能会经常出现. 不过, 既然使用了那么这些不可靠一定就不会对服务造成很大的影响

那么, 可靠就与不可靠相反了

`UDP`协议不会对丢包、检验失败等情况做出处理, 即使接收方没有正常收到数据, 接收方也不会有任何反应, 发送方更不会做出弥补. 我们说这是`UDP`协议更简单的一些代价

而`TCP`协议则不同. 使用`TCP`协议通信时, 如果出现了丢包等接收方没有收到数据的情况, `TCP`协议会有一些处理, 比如: 重传、控制流量等

那么, `TCP`协议是如何维护数据传输的可靠性的呢?

### `TCP`协议的确认应答机制

`TCP`协议会对接收方没有正常收到数据的情况做出弥补. 但是要实现这样的功能的第一个问题就是: **在这样的长距离通信中, 发送方(A)该如何确认发送的数据是丢了还是接收到了?**

答案是, **接收方(B)的回应**. 只要B收到数据之后, 给A发送一个回应, 那么A就可以确认数据已经发送到了

**即, 只要发送方 收到了应答, 那么发送方就可以确认刚刚发送的消息一定已经被收到了**

不过, **B发送的回应, B如何确认A是否收到了呢?**

答案是相同的, 如果 A收到B的回应之后, 再给B发送一个回应, 那么B就可以确认A收到了

就像这样:

![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/image-20240117001126901.webp)

你会发现, 如果想要做到每条消息都确定对方收到了, 是不可能的

因为 **在这样的长距离通信中, 永远有一条最新的消息是不能被确认的、没有应答的**

那么, 也就是说`TCP`协议也不是完全的可靠, 并且没有协议可以做到完全百分百的可靠

但是, `TCP`协议可以做到局部的可靠. 只要保证最新消息之前的消息都有了应答, 那么最新消息之前的数据就可以确定都已经接收到. 这就是`TCP`协议的可靠性

这样的机制, 被称为 **`TCP`协议的确认应答机制(ACK)**

---

不过, 这里又出现了其他问题: **使用`TCP`协议进行通信, 绝大多数情况下发送的报文是有很多个的. 那么,  发送方如何知道, 接收方应答的是哪一个报文呢?**

> 这个问题是什么意思呢? 
>
> `TCP`协议为了维护可靠性, 是有确认应答机制的
>
> 在使用`TCP`进行通信时, 发送方可能一下发送很多报文, 接收方可能会一下子收到很多报文, 并且 接收方可能会针对接收到的每一个报文都单独做出应答
>
> 但是, 报文在网络中传输是充满不确定性的, 即使按照一定的顺序发送, 也不一定会按照顺序到达
>
> 所以, 发送方收到的 接收方的应答报文 很大可能是乱序 (接收方实际也是这样)
>
> 那么, 发送方如何确定对方的应答报文, 应答的是哪一个报文呢?

`TCP`协议报头中, 有两个字段: **32位序号 和 32位确认序号**. 这两个字段, 可以解决上面这个问题

`TCP`协议在 **发送数据 填充报头时, 会填充序号**. 那么, 接收方接收到报文之后, 会根据报文的报头中填充的序号, 做出对应的应答. 即, **接收方 会在应答报文的报头中, 填充对应的确认序号**

**确认序号, 一般为接收到的报文序号+1, 表示 *确认序号之前的所有序号的报文都已经接收到*, 也同时表示接收方期望下次开始接收报文的序号**

用图片可以很形象的表示出来:

![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401302232394.webp)

同时, **接收端还可以通过接收到报文的序号对报文进行排序**

这就是`TCP`协议报头中 32位序号 和 32位确认序号 这两个字段的作用

从这两个序号的作用可以看出来, **发送端报头中的序号 与 接收端报头中的确认序号 是配套使用的**

那么, 也就意味着, **同一个报文的报头中, 序号与确认序号是相互独立、互不影响的**. 这也是 **`TCP`协议全双工** 的一种体现, 因为同一个报文中的序号和确认序号是相互独立的, 所以同一个报文中可以同时填充序号和确认序号, 那么就表示这个报文在具有应答功能的同时, 还携带有数据进行发送

> `TCP`协议规定了, 收到应答报文之后 发送方可以认为 **确认序号之前的所有序号的报文都已经接收到**
>
> 那么, 基于协议, 在实际实现时就可能会出现这样的情况:
>
> ![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401171656408.webp)
>
> 这是种实现被称为 **积累应答** 或 **延迟应答**, 可以有效提高通信效率
>
> 按照这样, 如果发送端发送了`1~10`序号的报文, 但是接收端只收到了`1~6`和`8~10`, 没有收到`7`
>
> 那么, 接收端应答报文中的确认序号 最高也只能填充`7`, 因为只有`7`之前序号的报文都收到了, 即使`8~10`也收到了, 也不会对其做出应答

> `TCP`协议通信时, 报文的起始序号实际是随机的
>
> 并且, **后续的序号与 初始序号和报文数据本身 有关**
>
> **序号协定的规则是什么呢?**
>
> 首先, **起始序号是在建立连接时协定好的, 是随机的**
>
> 并且, `TCP`协议会针对 **报文数据的每一个字节进行编号**
>
> **一个报文的序号, 就表示此 报文数据的第一个字节的编号**
>
> 如果存在此次`TCP`通信的第一个报文:
>
> ![|large](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401251711659.webp)
>
> 那么上图表示的这个报文中, `7214`表示此次`TCP`通信的初始序号, 同样也表示此报文数据的第一个字节的编号, 
>
> 那么第二个报文应为:
>
> ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401251657517.webp)
>
> 再之后的报文, 同样会按照相同的规则进行编号

### `TCP`协议的缓冲区及流量控制

在介绍`UDP`协议的文章中提到过, 无论是`UDP`协议还是`TCP`协议. 在发送报文时, 都不会直接将数据发送到网络, 而是将数据放入内核针对协议实现的 **发送缓冲区** 中(`UDP`没有真正的发送缓冲区). 接收数据也是相同的, 操作系统会将报文放入 **接收缓冲区** 中

`UDP`协议 在内核中没有实现真正的发送缓冲区, 只有接收缓冲区

而 `TCP`协议 则在内核中真正实现了 发送缓冲区和接收缓冲区

那么, 两个主机在使用`TCP`协议进行通信, 使用`write()/send()`和`read()/recv()`接口实现数据发送和接收所执行的操作, 简单理解可以看作:

![|lwide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401251738510.webp)

> ```cpp
> ssize_t write(int fd, const void *buf, size_t count);
> ssize_t send(int sockfd, const void *buf, size_t len, int flags);
> 
> ssize_t read(int fd, void *buf, size_t count);
> ssize_t recv(int sockfd, void *buf, size_t len, int flags);
> ```
>
> 这4个系统调用, 都需要指定一个`buf`

即, 使用`TCP`协议进行通信:

调用`write()/send()`发送数据 实际 是将数据 从进程指定的缓冲区中拷贝到了内核中`TCP`的发送缓冲区

调用`read()/recv()`读取数据 实际 是将数据 从内核中`TCP`的接收缓冲区拷贝到了进程指定的缓冲区中

也就是说, `write()/send()`实际并没有将数据发送走, 而只是将数据从用户拷贝到了内核数据中

> 实际上, 常用的`I/O`类函数, 本质上都是拷贝函数
>
> 即使使用`write()`向文件内写数据, 也只是将拷贝数据交给了操作系统, 并不是直接就写入了文件内

因为, `TCP`协议在内核中实现拥有发送缓冲区和接收缓冲区并且互不干扰, 所以`TCP`协议通信是全双工的

并且, 因为`TCP`协议发送数据, 是将数据拷贝到发送缓冲区, 然后由内核中的`TCP`协议自行决策(比如: 什么时候发、发多少、要不要进行一些调整...), 所以这个协议叫做 **传输控制协议(Transmission Control Protocol)**

#### `TCP`的流量控制

`TCP`协议在内核中是拥有发送缓冲区和接收缓冲区的, 那么 既然是缓冲区, 那就一定有一定的大小

并且, `TCP`协议通信是可靠的, 那么对发送出去的数据就不能不管不顾, 不能像`UDP`那样(如果接收缓冲区满了, 再发送过来的数据报就丢掉不管了)

那么, 如果`TCP`协议发送数据过快, 导致接受方的接收缓冲区满了, 怎么办? 继续快速的发送数据, 然后接收方来不及接收 直接丢包不管吗?

`TCP`协议并不会这样. `TCP`协议为了保障通信效率, 拥有自己的流量控制功能

**`TCP`协议可以获取接收方当前接收数据的能力, 来调节发送方发送数据的速率**

也就是说, 如果`client`需要向`server`发送数据, `client`可以根据`server`端的接收能力, 动态调控自己发送数据的速率

但是, `client`该如何知道`server`的接受能力呢? `server`的接收能力又如何表示呢?

缓冲区是有大小的, 那么, `server`的 **接收能力 就可以通过 接收缓冲区的剩余空间大小来表示**

那么, `client`该如何获取`server`的接收缓冲区剩余空间大小呢?

`TCP`协议报头中, 有一个字段是 **16位窗口大小**, 这个 **窗口大小表示的就是接收缓冲区剩余空间的大小**

如此一来, `client`接收到`server`的应答时, 就可以获取到`server`的窗口大小, 就可以调节自己发送速率, 进而实现流量控制

即, **发送方 可以通过 读取接收方的应答报头中填充的窗口大小, 来了解接收方接受数据的能力, 然后来调控自己发送数据的能力**

> 问题:
>
> 既然在使用`TCP`协议正常通信时, 发送方可以通过接收方的应答报文中的窗口大小, 来获取接收方的接收能力
>
> 那么, **发送方在第一次发送数据的时候, 如何知晓接收方的窗口大小呢?**

### `TCP`报文类型 标记位

我们都知道, 在使用`TCP`协议进行通信的时候, 需要先"三次握手"建立连接, 然后才能实现正常的数据通信, 并且在通信结束的时候, 还需要"四次挥手"断开连接

为了方便`TCP`通信时需要做出一些特殊的处理, 实际上`TCP`报文是存在类型的, 针对不同类型的`TCP`报文 

`TCP`协议会做出不同的处理和响应:

1. 建立连接过程中发送的报文, `TCP`协议需要分辨出这个报文是建立连接用的, 然后会做出对应的处理与响应
2. 正常通信过程中发送的报文, `TCP`协议需要分辨出这个报文是正常通信用的, 然后会做出对应的处理与响应
3. 断开连接过程中发送的报文, `TCP`协议需要分辨出这个报文是断开连接用的, 然后会做出对应的处理与响应
4. ...

而`TCP`报文的类型, 则是通过`TCP`报头中的 **6个标记位** 来标识、分区的:

![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401182201647.webp)

下面, 就来认识一下这6个标记位:

#### 1. `SYN`

这个标记位全称是`Synchronize Sequence Numbers`, 叫做 **同步标记位**

是在"三次握手"建立连接时使用的, 使用时需要将此标志位设置为1

#### 2. `FIN`

这个标记位全称是`Finish`, 叫做 **结束标记位**

是在"四次挥手"断开连接时使用的, 使用时需要将此标志位设置为1

---

`SYN`和`FIN`这两个标志位的具体使用方法, 在具体介绍 `TCP`的"三次握手"和"四次挥手"时再进行介绍

#### 3. `ACK`

这个标记位的名字, 在上面介绍`TCP`确认应答机制时见到过, 全称是`Acknowledgement Number`, 叫做 **确认标记位**

按照名字来说, 此标记位表示 该报文是对历史报文的确认, 应答报文应该设置此标记位为1. 但是, 实际上`ACK`标记位的使用 **不仅仅只能作确认用**

因为一般来说, 应答报文也是可以携带数据的, 而应答报文是需要设置`ACK`标记位的, 也就是说`ACK`标记位也允许在传输数据时设置

那么, **在`TCP`连接建立完成之后, 实际使用`TCP`协议进行通信时, 大部分的`TCP`报文都会将`ACK`标记位设置为1**

#### 4. `PSH`

这个标记位的全称是`Push Function`, 叫做 **推送标记位**

要理解这个标记位是干什么用的, 需要先介绍一些Linux操作系统`I/O`操作的特点

上面介绍过`TCP`协议是拥有接收缓冲区的, 而在`TCP`通信 调用`read()`是从`TCP`的接收缓冲区内拿数据到进程设置的缓冲区中 

而`read()`是一个阻塞式的接口, 当`TCP`接收缓冲区没有数据时, 调用`read()`的进程也好、线程也好 都会阻塞住, 直到`TCP`的接收缓冲区有数据了, `read()`才会继续执行读取数据. 这个过程中, **`read()`只有主动调用 才会检测`TCP`接收缓冲区是否有数据, 然后才会阻塞或读取数据** 的. 但是, 这样的阻塞式`I/O`并没有非常高效

所以, Linux实际提供的还有非阻塞式`I/O`接口(暂时不具体介绍). 也就是说, 应用层可以非阻塞式的从`TCP`接收缓冲区读取数据. 大概就是, 当`TCP`接收缓冲区没有数据的时候, 即使调用了非阻塞式接口, 进程或线程也不会阻塞住, 会结束执行. 而, 当`TCP`接收缓冲区中的数据大小达到一定阈值了(即让应用层读取数据的条件满足了), 内核会去通知进程或线程 可以读取数据了, 然后才会重新调用非阻塞式接口, 然后将数据读取到应用层. 也就是说, **这样的非阻塞式接口, 是不需要主动调用才能接收数据的(当然也可以主动调用), 它可以等待内核的通知, 然后再调用 实现读取数据**

而设置`PSH`标志位, 就是 **让内核通知应用层马上、尽快读取`TCP`接收缓冲区内的数据** 的. 即使`TCP`接收缓冲区中的数据大小 还没有达到需要让内核通知应用层的阈值(即, 即使让应用层读取数据的条件并没有满足)

#### 5. `URG`

这个标记位的全称是`Urgent Pointer`, 叫做 **紧急指针标记位**

我们知道, 报文在网络中路由时, 有些报文即使发送的早, 也不一定就会很早的到达接收方

那么也就是说, 在进行`TCP`通信时, 即使是按照序号的大小顺序发送的报文, 但是报文到达接收方的顺序也不一定是发送时的顺序. 即, 报文按顺序发送, 却乱序到达. 这是不可靠的一种体现, 而`TCP`协议是可靠的, 那么接收方就需要保证 接收到的数据是按照顺序的

所以, 接收方可以根据已经发送过来的报文的序号, 对报文进行排序并解包, 如果有数据没有到, 那就应答已经到了数据序号. 让后将排好顺序的报文数据再放到接收缓冲区中. 比如, 如果按照`1 2 3 4 5 6 7 8`发送数据, 数据却按照`3 2 4 1 5 7 8 6`的顺序到达了, 如果接收方当时只接受到了`3 2 4 1 5 7 8`, 还没接收到`6`, 那么就会对已经接收到的报文排序`1 2 3 4 5 7 8`, 发现`6`之前的报文都收到了, 那么接收方就会对`1~5序号`报文进行解包, 并应答确认序号`6`

这样, **`TCP`可以实现报文数据按照发送顺序到达**

但是, 这样会有另外的问题: *有些时候, 应用层需要处理的某些数据优先级比较高. 那么, 此时优先级高的数据如果还按照发送顺序进行接收, 报文到达的早还好, 如果报文到达的很晚, 好像高优先级就没有意义了*

那么, 要解决这个问题, 就需要用到`URG`标记位了

当存在紧急数据需要发送时, `TCP`协议的发送方就会设置`URG`标志位, 接收方接收到报文读取到`URG`被设置为1时, 就会选择将紧急数据存入 **外带缓冲区**. 应用层可以直接从外带缓冲区读取紧急数据, 所以紧急数据也叫做外带数据

不过, **一个报文中的紧急数据的大小只能是1字节**, 这与`TCP`报头的另一个字段有关: **16位紧急指针**

`TCP`报头中的紧急指针字段, 实际上就是指紧急数据在本报文数据中的字节偏移量, 并且 只能保存一个偏移量, 也就是说, 一个`TCP`报文中只能标识1个紧急数据. 这也是为什么紧急数据只能是1字节

---

还有一个标记位没有介绍: `RST`. 为了更加理解这个标记位, 需要先介绍一下`TCP`"三次握手"的过程

### `TCP`的"三次握手" 以及`RST`标记位

`TCP`协议是有连接的传输层协议

`TCP`协议建立连接的过程, 叫做"三次握手", 这个过程具体是什么? 为什么是三次? 这两个问题可以分析一下

`TCP`"三次握手"建立连接的过程, 用图片展示是这样的:

![|huger](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401271718575.webp)

> 注意, 通信中发送的 `SYN` `SYN+ACK` `ACK`, 并不是发送报文中携带的数据, 而是指发送的报文报头中设置的标记位

此图中, `Client`代表 **客户端** `Server`代表 **服务端**, **不同颜色的片段表示不同的状态**

那么, 这个"三次握手"的过程就是: 

1. 客户端先发送连接请求, 即 将`TCP`报文中`SYN`标记位设置为1, 然后再将整个报文发送给服务端(一般情况下不会携带数据)

    客户端发送了此报文之后, 客户端进入`SYN_SENT`状态, 表示已发送了建立连接的请求

2. 如果服务端收到了 客户端发送的连接请求, 那么服务端就会应答客户端的请求, 即 将`TCP`报文中`SYN`和`ACK`标记位都设置为1, 然后再将整个应答报文发送给客户端(同样一般不会携带数据)

    服务端发送了此 应答报文之后, 服务端进入`SYN_RCVD`状态, 表示已经应答了客户端的连接请求

3. 然后客户端就应该收到 来自服务端的应答报文 之后, 客户端就需要再向服务端发送一个应答, 即 客户端将`TCP`报文中`ACK`标记位设置为1, 然后将报文发送给服务端

    客户端发送了此次应答报文之后, 客户端就会进入`ESTABLISHED`状态, 客户端认为连接建立成功

4. 最后, 服务端应该收到来自客户端的应答报文, 收到之后, 服务端不会再发送应答报文, 而是进入`ESTABLISHED`状态, 服务端认为连接建立成功

"三次握手"的实际就是 客户端和服务端在互相发送报文, 用来确认连接的过程

#### 如何理解简单`TCP`的连接

`TCP`协议是面向连接的, 那么 什么是`TCP`连接呢? 如何理解`TCP`连接呢?

一个主机是可以同时建立大量的连接的, 那么操作系统就需要同时维护、管理大量的连接

按照以往操作系统管理大量进程、文件等的经验, 操作系统一定会针对每个连接 均维护 包含此连接所有属性的结构体. 不过, 由于`TCP`连接的管理较为复杂, 所以对应需要维护的结构体不止一个

那么, 也就是说, 当客户端或服务端 **为了维护`TCP`连接 创建了对应的结构体对象 并 已经完成了结构体内数据的填充**, 就表示 客户端或服务端认为此次`TCP`连接已完成且成功

#### 为什么是"三次握手"

上面 介绍了"三次握手"的过程, 但是 为什么是三次?

**一次不行吗?**

我们已经了解到, 当服务端针对此次`TCP`连接 创建并维护了对应的结构体对象 并 完成了结构体数据的填充时, 服务端就认为连接建立完成

既然是操作系统创建维护一些结构体, 那么就一定有时间和资源上的消耗

如果是"一次握手", 就表示 客户端发送`SYN`连接请求之后, 就直接认为自己创建好了连接, 服务端收到请求 不需要应答, 服务端就同样直接认为连接已建立

虽然, "一次握手"也同样可能成功的建立连接

但是, **如果只是"一次握手" 就会出现一些问题:**

1. 客户端和服务端无法正确协定、同步 双方的初始序号

    `TCP`报头存在 **序号**, 此字段的初始值是在建立连接时, 客户端和服务端互相协定、同步的

    如果只是"一次握手", 那么只能同步客户端的初始序号, 因为只有客户端发送了携带初始序号的报文

2. 由于网络延迟, 客户端可能多次发送连接请求, 服务端就有可能多次建立连接

    服务端多次建立了连接, 即 多次创建了 一些维护连接所需的结构体, 但是只有一套是有效的

    这样, 会造成对服务端资源的无效占用

**两次不行吗?**

如果是"两次握手", 就表示 客户端先发送`SYN`连接请求, 服务端收到请求 需要`SYN+ACK`应答, 然后服务端认为连接建立完成, 客户端收到服务端的应答之后, 客户端认为连接建立完成

我们知道, 客户端和服务端认为连接建立完成的标志是 系统已经创建并填充完成了 一系列维护`TCP`连接所需的结构体

那么如果"两次握手", 则是 **服务端系统先完成了 创建并填充 一系列维护连接所需的结构体**

这就可能出现一个问题: 如果客户端不断地发送请求, 但是不接收服务端的请求, 然后导致 服务端不断地 维护`TCP`连接, 而客户端并不维护连接.

这就实现了对服务端主机的攻击: **服务端会不断地消耗时间和空间资源, 用于维护`TCP`连接, 而客户端不会**

并且, 由于 **服务端依旧是 仅接收一次客户端的报文 就确认连接已建立**, 所以还可能会出现 仅"一次握手"出现的问题:

1. 由于网络延迟, 客户端可能多次发送连接请求, 服务端就有可能多次建立连接

    服务端多次建立了连接, 即 多次创建了 一些维护连接所需的结构体, 但是只有一套是有效的

    这样, 会造成对服务端资源的无效占用

> "两次握手", 理论上来说 不会出现无法协定、同步通信双方初始序号的问题
>
> 因为, 客户端发送连接请求可以携带初始序号, 服务端进行应答也可以携带初始序号
>
> 即使存在网络延迟, 导致客户端发送了多个连接请求. 服务端也会针对多个连接请求一一进行应答
>
> 所有应答报文都会填充对应的确认序号和初始序号, 所以客户端只要收到了应答报文, 就可以确认服务端应答的目标 以及 服务端的初始序号. 然后, 连接建立成功
>
> 如果, 客户端没有收到应答报文, 那这就意味着连接还没有建立成功, 客户端可能会继续发送请求, 直到成功接收应答报文

**如果是三次呢?**

"三次握手"的过程已经简单的分析了一下

![|huge](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401252027280.webp)

从图中可以看到, `Client`率先进入了`ESTABLISHED`状态, 也就是说 **`Client`率先完成了维护`TCP`连接操作**

然后, `Server`进入了`ESTABLISHED`状态, 这样 让客户端先完成维护连接的操作, 可以避免像"两次握手"那样 服务端被攻击, 至少客户端也要付出相同的代价

其次, 因为在`Client`和`Server`进入`ESTABLISHED`状态之前, 都经历了一收一发, 所以不会出现 无法正确协定和同步双方初始序号的情况

并且, "三次握手"通过三次报文传输, 顺便完成了 客户端的发送(`SYN`请求)和接收(`SYN+ACK`应答)能力的检测 以及 服务端的发送(`SYN+ACK`应答)和接收(`ACK`应答)能力的检测

"三次握手"是可以完成上面这些功能的最少的次数, 如果"四次握手"或更多次数的握手, 也只是徒增连接消耗罢了

#### 协定、同步双方初始序号

上面展示"三次握手"过程的图, 没有展示出 通信双方同步初始序号的过程

"三次握手"过程可以这样展示:

![|huge](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401252033292.webp)

> `SYN` `ACK` 大写的, 表示设置的标记位
>
> `seq` `ack` 小写的, 表示序号 和 确认序号

整个 协定、同步初始序号的过程是:

1. 客户端发送连接请求, 携带随机初始序号的`seq = x`

2. 服务端收到请求, **读取到客户端的初始序号**, 应答报文 携带随机初始序号的`seq = y`, 且填充确认序号`ack = x+1`

3. 客户端收到应答, 读取确认序号 确认服务端已同步客户端初始序号, 同时 **读取到服务端的初始序号**, 然后 应答报文 填充序号`seq = x+1`和确认序号`ack = y+1`

    客户端确认连接建立

4. 服务端收到应答, 读取确认序号 确认客户端已同步服务端初始序号

    服务端确认连接建立

整个过程中, **客户端和服务端, 都是经过一发一收 读取收到确认序号之后, 才确认的初始序号已同步**

"一次握手"和"两次握手"无法完善这个过程

> 了解了"三次握手"的过程, 回到上面提到的一个问题:
>
> **发送方如何在第一次发送数据之前, 就知晓接收方的窗口大小呢?**
>
> 这个答案就是: 双方会 **在"三次握手"阶段对窗口大小进行交换、同步**

#### 6. `RST`标记位

"三次握手"的过程中, 报文的发送是需要时间的

在客户端进行第三次握手之后, 客户端实际就已经认为本次`TCP`连接已经建立完成了

客户端完成连接建立之后, 会干什么? 会向服务端发送数据

但是, 有一个问题是, 如果服务端没有收到第三次握手的报文, 但是客户端已经向服务端开始发送数据了, 怎么办?

在服务端还在等待第三次握手的报文时, 服务端还没有进入`ESTABLISHED`状态, 客户端已经发送通信数据到服务端了, 此时 **服务端就会意识到 `TCP`连接出了问题**

然后 服务端就会向客户端发送 设置了`RST`标记位的报文, 让客户端重置`TCP`连接并重新进行"三次握手"

这就是`RST`标记位的作用, 让客户端重新建立`TCP`连接, 所以`RST`标记位 叫做复位标记位

> 除了上面出现的场景, `RST`还可以用于由于长时间不进行通信, 被服务器单方面断掉的`TCP`连接中

### `TCP`的超时重传机制

`TCP`的超时重传机制表示, **在`TCP`通信中, 如果一端长时间没有收到来自对端的应答, 那么就会重新发送没有收到应答的报文**

但是, 长时间没有收到对端应答有两种情况:

1. 报文根本就没有发送到对端, 在传输过程中丢包了
2. 对端接收到报文了, 并且也发送了应答报文, 但是对端的应答却在传输的过程中丢包了

这两种情况的区别是, `1. 对端没收到数据` `2. 对端收到了数据`

1. 对端没有收到数据

    此时, 只需要在超时之后 将报文重新发送给对端 就可以了

2. 对端收到了数据

    如果对端已经收到了数据, 但是对端的应答报文丢了

    那么, 当报文重新发送给对端之后, 对端会再次发送应答报文

    但是, 此时 **对端就会接收到重复的数据**. 但重复的报文、数据是没用的 需要丢弃, 所以 `TCP`协议需要有能力识别接收的报文是否重复

    这就要用到`TCP`报文的 **序号字段**. 只要两个报文的序号字段相同, 就说明收到了相同的报文

> `TCP`协议的超时重传机制, 说明了 `TCP`报文在发送出去 或 接收到之后, 并不会立刻丢弃, 而是会存储一段时间
>
> 这也是 `TCP`超时重传机制的基础

那么, **`TCP`如何界定 是否超时?**

最理想的情况, 就是可以找到一个最短的时间, 保证此次发送之后"确认应答一定能在这个时间内返回".

但是, 网络环境是会变化的, 所以这个最短的时间也是不可能固定下来的

所以Linux中`TCP`协议就需要自行的界定、计算 超时边界

不过, 重传不会一直进行, 当重传累计到一定的重传次数, `TCP`认为网络或者对端主机出现异常, 强制关闭连接

> 关于超时的设定:
>
> 如果超时时间设的太长, 会影响整体的重传效率
>
> 如果超时时间设的太短, 有可能会频繁发送重复的包

### `TCP`的"四次挥手"

`TCP`协议建立连接 需要"三次握手". "三次挥手"完成之后, 连接双方就可以正常通信了

直到最后`TCP`协议断开连接 需要"四次挥手":

![|huger](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401271707265.webp)

从图中看, `TCP`的"四次挥手", 是由 **两端分别发送`FIN`报文, 对端再应答`ACK`报文** 形成的

整个过程是这样的:

1. 先发送`FIN`的一端(主动端A) 在接收到对端(被动端B)的`ACK`之后, 会进入`FIN_WAIT_2`状态, 而不是直接`CLOSED`
2. 并且, B端接收到`FIN`之后, 也没有直接应答`FIN`关闭连接. 而是, 进入了`CLOSE_WAIT`状态
3. 然后, B端才发送了`FIN`报文, 并进入`LAST_ACK`状态, 直到收到A端的`ACK`应答报文
4. A端收到B端发送的`FIN`报文, 并发送`ACK`应答报文之后, 并没有直接进入`CLOSED`状态, 而是先进入了`TIME_WAIT`状态
5. > "四次挥手"的主动发起者, 可以是客户端, 也可以是服务端
    >
    > 所以, "四次挥手"用主动端和被动端来区分状态

可以看到, `TCP`"四次挥手"的过程中, 双方会进入许多的状态:

1. 先发送`FIN`的一端, 会依次进入`FIN_WAIT_1` `FIN_WAIT_2` `TIME_WAIT`, 最后才`CLOSED`
2. 后发送的一端, 则会在接收到`FIN`之后, 依次进入`CLOSE_WAIT` `LAST_WAIT`, 然后才`COLSED`

> 哪一方发送了`FIN`报文, 就表示这一方想要断开连接了, 此端应用层不会再向对端发送数据了

---

那么了解了"四次挥手"的整个过程, 一定会有一个疑问: **A端发送`FIN`报文之后, 为什么B端没有直接应答`FIN`, 而是进入了`CLOSE_WAIT`状态?**

答案是, **为了维护数据传输的可靠性**

A端向B端发送`FIN`报文, 表示A端不准备通信了, 实际也就表示A端应用层不会再向B端发送数据了

但是, A端没有数据发送了, B端却不一定. 毕竟, `TCP`协议是存在发送缓冲区的, 也就是说 B端可能还有数据没有向A端发送呢, 如果直接和A端一起断开连接, 那么还没有发送的数据怎么办?

所以, 虽然A端发送了`FIN`报文, 想要断开连接, 但是B端可能并不想现在据断开连接, 所以就可能不会直接应答`FIN`

即, 当被动端不想直接断开连接时, 就只应答`ACK`报文, 并进入`CLOSE_WAIT`状态

直到, 被动端也没有要发送的数据了, 被动端才会发送`FIN`报文, 并进入`LAST_ACK`状态

> 如果, 主动端发送`FIN`报文时, 被动端也想要断开连接了
>
> 那么, B端就可能会应答`ACK+FIN`的报文
>
> 不过, 这并不是一般情况, 我们还是要讨论一般情况滴

主动端接收到被动端的`FIN`报文之后, 向被动端应答最后一个`ACK`报文, 并进入`TIME_WAIT`状态 持续一段时间后, 正式关闭连接

被动端在收到主动端的`ACK`应答报文之后, 正式关闭连接

#### "四次挥手"状态分析

我们已经了解了"四次挥手"的大致过程, "四次挥手"过程中 挥手双方 会进入这么多的状态

那么, **双方为什么要进入这么多状态? 这些状态都有什么存在意义?**

下面, 就来解释一下:

**针对主动端:**

1. 主动端(我)发送`FIN`报文之后, 会进入 **`FIN_WAIT_1`** 状态

    **`FIN_WAIT_1`** 状态 的作用

    1. 表示我已经主动发送`FIN`报文, 告诉对端 自己想要断开连接
    2. 防止因网络延迟或其他原因, 我没有收到对端的`ACK`应答报文. 出现此情况, 还需要超时重传`FIN`报文
    3. 进入`FIN_WAIT_1`状态开始, 我就关闭了`TCP`发送缓冲区, 应用层不会再向对端发送数据, 同时让对端也了解到这一点

    此状态持续时间, 取决于什么时候收到对端的`ACK`应答报文

2. 主动端接收到对端的`ACK`报文之后, 会进入 **`FIN_WAIT_2`** 状态

    **`FIN_WAIT_2`** 状态 的作用

    1. 表示我已经收到了对端的`ACK`应答报文
    2. 并了解到 对端还不想关闭连接, 所以 我需要保持`TCP`接收缓冲区不关闭, 保持此端接收数据的功能

    此状态持续时间, 取决于对端什么时候想要关闭连接, 即 什么时候收到对端发送的`FIN`报文

3. 主动端接收到对端的`FIN`报文, 并作出应答之后, 会进入 **`TIME_WAIT`** 状态

    **`TIME_WAIT`** 状态 的作用

    1. 表示我已经收到了对端发送的`FIN`报文, 了解到对端数据也发完了, 对端也想要关闭连接了

    2. 此端也已经发送了`ACK`应答报文, 告诉对端收到了`FIN`报文

    3. 但是, 此状态并不会直接结束, 而是会持续一段时间

        原因一: 对端发送的数据可能还在传输中, 所以并不能马上关闭连接

        原因而: 对端可能没有收到我发送的`ACK`应答, 对端可能还会发送`FIN`报文, 我还得再次`ACK`应答, 保证对端收到了`ACK`之后 正确关闭连接

    此状态持续时间, 不能过长 不能过短, `TCP`协议推荐值为`2*MSL` (后面分析解释)

那么

**针对被动端:**

1. 被动端收到对端的`FIN`报文, 并作出应答之后, 会进入 **`CLOSE_WAIT`** 状态

    **`CLOSE_WAIT`** 状态 的作用

    1. 表示被动端已经收到了对端的`FIN`报文, 知道了对端要关闭连接 并且已经关闭了发送缓冲区 不再给被动端发送数据了

    2. 不过, 被动端暂时还不想关闭连接, `TCP`发送缓冲区内还有数据没有发送完, 所以需要维持`CLOSE_WAIT`状态

    3. 并且, 需要在 对端没有收到`ACK`应答, 再次发送`FIN`报文时, 重新应答`ACK`报文

    4. 还有, 被动端收到了`FIN`报文, 也会向应用层关闭发送缓冲区

        提醒应用层, 将`write()`或`send()`缓冲区里已经存在的数据发走之后, 就不要在发送数据了, 发送缓冲区要关闭了

        不然, 还一直有数据要发送, 还要一直消耗双方资源

    此状态持续时间, 取决于什么时候`TCP`发送缓冲区的数据发完, 并且与`close()`调用有关 (后面分析解释)

2. 被动端数据发送完, 调用`close()` 发送`FIN`报文之后, 会进入 **`LAST_ACK`** 状态

    **`LAST_ACK`** 状态 的作用

    1. 表示被动端已经发送了`FIN`报文, 也要关闭连接了

    2. 等待对端的`ACK`应答报文, 即 需要知道 对端已经收到了被动端的`FIN`报文

        如果长时间没有收到对端的`ACK`应答报文, 被动端需要重新发送`FIN`报文

        所以, 需要维护`LAST_ACK`状态

    直到收到对端的`ACK`应答, 才会关闭连接

在上面这5个状态中, 有2个状态很重要: **被动端的`COLSE_WAIT`** 和 **主动端的`TIME_WAIT`**

并且, 这两种状态也是"四次挥手"过程中, 最容易观察到的

#### 观察、分析`CLOSE_WAIT`和`TIME_WAIT`

我们可以实现一个最简单的`TCP`服务器, 并使用`telnet`建立连接查看端口的状态

`tcpServer.cpp`

```cpp
#pragma once

#include <iostream>
#include <string>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <unistd.h>
#include <sys/wait.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>

#define SOCKET_ERR  1
#define BIND_ERR    2
#define LISTEN_ERR  3
#define USE_ERR     4
#define CONNECT_ERR 5
#define FORK_ERR    6
#define WAIT_ERR    7

#define BUFFER_SIZE 1024

class tcpServer {
public:
    tcpServer(uint16_t port, const std::string& ip = "")
        : _port(port)
        , _ip(ip)
        , _listenSock(-1) {}

    void init() {
        _listenSock = socket(AF_INET, SOCK_STREAM, 0);

        if (_listenSock < 0) {
            // 套接字文件描述符创建失败
            printf("socket() faild:: %s : %d\n", strerror(errno), _listenSock);
            exit(SOCKET_ERR); // 创建套接字失败 以 SOCKET_ERR 退出
        }
        printf("socket create success: %d\n", _listenSock);

        // 套接字创建成功, 就需要将向 sockaddr_in 里填充网络信息
        struct sockaddr_in local;
        std::memset(&local, 0, sizeof(local));

        // 填充网络信息
        local.sin_family = AF_INET;
        local.sin_port = htons(_port);
        _ip.empty() ? (local.sin_addr.s_addr = htonl(INADDR_ANY)) : (inet_aton(_ip.c_str(), &local.sin_addr));

        // 绑定网络信息到主机
        if (bind(_listenSock, (const struct sockaddr*)&local, sizeof(local)) == -1) {
            printf("bind() faild:: %s : %d\n", strerror(errno), _listenSock);
            exit(BIND_ERR);
        }
        printf("socket bind success : %d\n", _listenSock);

        if (listen(_listenSock, 2) == -1) {
            printf("listen() faild:: %s : %d\n", strerror(errno), _listenSock);
            exit(LISTEN_ERR);
        }
        printf("listen success : %d\n", _listenSock);
        // 开始监听之后, 别的主机就可以发送连接请求了.
    }

    // 服务器初始化完成之后, 就可以启动了
    void loop() {
        while (true) {
            sleep(1);
            struct sockaddr_in peer;          // 输出型参数 接受所连接主机客户端网络信息
            socklen_t peerLen = sizeof(peer); // 输入输出型参数
            
            int serviceSock = accept(_listenSock, (struct sockaddr*)&peer, &peerLen);
            if (serviceSock == -1) {
                printf("accept() faild:: %s : %d\n", strerror(errno), serviceSock);
                continue;
            }
            sleep(120);
	  		close(serviceSock);
        }
    }

private:
    uint16_t _port; // 端口号
    std::string _ip;
    int _listenSock; // 服务器套接字文件描述符
};

void Usage(std::string proc) {
    std::cerr << "Usage:: \n\t" << proc << " port ip" << std::endl;
    std::cerr << "example:: \n\t" << proc << " 8080 127.0.0.1" << std::endl;
}

int main(int argc, char* argv[]) {
    if (argc != 3 && argc != 2) {
        Usage(argv[0]);
        exit(USE_ERR);
    }
    uint16_t port = atoi(argv[1]);
    std::string ip;
    if (argc == 3) {
        ip = argv[2];
    }

    tcpServer svr(port, ip);

    svr.init();
    svr.loop();

    return 0;
}
```

这是一个非常简单的`tcpServer`, 编译、运行起来后 就可以对其发起连接了

这个服务器需要注意的是:

1. **`listen(_listenSock, 2)`, `listen()`第二个参数设置为`2`**
2. **`accept()`接口没有被调用, `close()`同样没有被调用**

##### `CLOSE_WAIT`

**`CLOSE_WAIT`是被动端会进入的状态**

将程序编译、运行起来, 使用`telnet`进行连接, 使用`netstat`命令查看状态:

1. 服务器运行起来, 暂时没有建立连接时

    使用`netstat -nlpt`查看, 系统中处于`LISTEN`状态的`TCP`服务

    ![|huger](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401282054317.webp)

2. 当使用`telnet`向服务器发起连接之后

    使用`netstat -npt`查看`TCP`服务的连接状态

    ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401282059635.webp)

    可以看到, 系统维护有 **从客户端到服务端的连接** 和 **从服务端到客户端的连接**, 并且状态都处于`ESTABLISHED`

    这可以说明什么?

    要知道, 上面的服务代码是没有调用`accept()`的 

    **可能很多人认为`accept()`接口是用来同意连接请求的, 但实际并不是的, 因为即使没有调用`accept()`, "三次握手"依然是正常完成了, 双端正常进入了`ESTABLISHED`状态**

    所以, 这个现象说明 **"三次握手"完成与否, 是与应用层是否调用`accept()`无关的**

    并且说明了, **`accept()`接口的功能 只是将内核中已经与客户端建立好的`TCP`连接数据、信息, "拿"到进程中使用**

3. 如果使用`telnet`向服务器发起更多连接(一共4次)

    再次使用`netstat -npt`查看`TCP`服务的连接状态

    ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401282115992.webp)

    可以看到, `telnet`4次尝试向服务端建立连接, 系统成功建立了3条`TCP`连接

    有1条没有成功建立, 而是 **客户端进入了`SYN_SENT`状态**, 也就表示服务端好像没有应答

    出现这种现象的原因是: **`listen()`的第二个参数设置为了`2`, 并且没有调用`accept()`将建立好的连接拿走**

    > 如果`listen()`的第二个参数设置为1, 那么 就只能成功连接2条
    >
    > 如果`listen()`的第二个参数设置为0, 那么 就只能成功连接1条
    >
    > **前提是不调用`accept()`**
    >
    > 很容易测试, 可以试一下
    >
    > `listen()`第二个参数的具体作用, 后面再介绍

4. 重新使用`telnet`向服务器发起连接, 并且记录从建立连接, 到断开连接, 服务端连接状态的变化

    ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401282247759.webp)

    可以看到:

    1. 客户端发起连接之后, 服务端和客户端相互维护连接, 均进入`ESTABLISHED`状态

    2. 客户端主动关闭连接之后, 服务端进入`CLOSE_WAIT`状态

    3. 之后, 如果服务端没有停止运行, 服务端会一直处于`CLOSE_WAIT`状态

    4. 服务端停止运行了, 相应的连接状态才关闭

    5. > 客户端(主动端)主动关闭连接之后, 可以看到 先进入了`FIN_WAIT_2`状态
        >
        > 并且, 在之后的观察中 可以发现, 主动端完整的关闭了连接
        >
        > 但是, `TCP`"四次挥手"规定, 只要主动端没有收到被动端发送的`FIN`报文, 就会一直处于`FIN_WAIT_2`状态吗?
        >
        > 理论上是这样的, 但是 Linux在实现上并没有这样实现:
        >
        > 执行`man tcp`的命令, 并搜索`tcp_fin_timeout`:
        >
        > ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401282259457.webp)
        >
        > **tcp_fin_timeout（整数; 默认值: 60; 自 Linux2.2 起）**
        >
        > **它指定了在强制关闭套接字之前, 等待最终`FIN`数据包的秒数. 这违反了`TCP`规范, 但却是防止服务攻击所必需的. 在 Linux2.2 中, 默认值为 180**
        >
        > 也就是, 说Linux针对 主动端 等待 被动端的`FIN`报文 设定了一个时间限制. 只要 主动端等待的时间 超出了这个时间限制, 主动端就会强制关闭连接
        >
        > 这也就是为什么, 上面 客户端进入`FIN_WAIT_2`一段时间之后, 突然不见了

    可以发现, 客户端(主动端)关闭连接, 服务端(被动端)好像会一直处于`CLOSE_WAIT`状态

    服务端处于`CLOSE_WAIT`状态, 但是客户端已经关闭了连接, 就会导致服务端一直无效占用系统资源

    至于服务端为什么会一直处于`CLOSE_WAIT`状态, 实际是因为服务端没有调用`close()`关闭`socket`

5. 如果我们将服务端代码中被注释掉的部分解开, 然后再编译运行, 并且使用`telnet`连接

    可以先预测一下结果: 

    代码在`accept()`之后`sleep(120)`, 然后再调用`close()`

    也就是说`accept()`将连接拿到进程中的`120s`之后, 服务端会`close()`掉`socket`

    那么, 如果由客户端在这`120s`内 主动断开连接, 那么此次服务端不会一直处于`CLOSE_WAIT`状态

    实际的结果:

    ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401291554118.webp)

    实际的结果, 也正如预测的那样, 服务端基本是在连接建立成功`120s`之后, 调用了`close()`关闭了连接, 从而解决了一直处于`CLOSE_WAIT`的情况

    整个过程中, 服务端是没有停止运行的, 只是在最后调用了`close()`关闭了`socket`

    > 客户端的`FIN_WAIT_2`状态也确实只维持了`60s`

从观察、分析的结果来看, **如果被动端 不调用`close()` 关闭此次连接创建的`socket`, 那么被动端就会一直处于`CLOSE_WAIT`状态, 即使 已经不会再有任何通信**

这就会导致, **被动端的系统资源得不到释放, 一直被无效占用**, 所以, **无论是客户端还是服务端, 双端在通信完成之后, 一定要调用`close()`关闭`socket`释放资源**

##### `TIME_WAIT`

**`TIME_WAIT`是主动端会进入的状态**

要观察`TIME_WAIT`状态, 需要让客户端收到服务端发送的`FIN`报文, 所以 我们需要将服务端代码中`sleep(120)`, 调整到 `sleep(50)` 或 更低, 主要是为了保证客户端在`FIN_WAIT_2`状态维持时间内 收到 服务端的`FIN`报文

我设置为`sleep(40)`

依旧将程序编译、运行起来, 使用`telnet`进行连接, 使用`netstat`命令查看状态:

`telnet`发起连接之后, 主动关闭连接, 并查看客户端状态变化:

![|lwide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401291631389.webp)

可以看到, 在连接成功建立(24:01) 的`40s`左右之后(24:40), 被动端(服务端)调用`close()` 发送`FIN`报文

主动端(客户端)收到`FIN`报文并应答, 进入`TIME_WAIT`状态(24:40), 被动端收到应答关闭连接

主动端进入`TIME_WAIT`约`60s`后(25:41), 关闭连接. 因为`25:34`时 主动端依旧处于`TIME_WAIT`, `25:41`就关闭了连接

从观察的结果来看`TIME_WAIT`大致维持了`60s`

---

**那么**

**1. 为什么主动端要维护一个`TIME_WAIT`状态?**

**2. 为什么`TIME_WAIT`状态维持的时间是多少? 为什么?**

> 首先关于第一个问题:
>
> `TIME_WAIT`是"四次挥手"的主动发起方需要维持的一个状态
>
> 我们知道, 主动端想要关闭连接, 被动端可能还存在数据未发送完毕 并不想要关闭连接
>
> 主动端是如何进入`TIME_WAIT`状态的呢? 是被动端将数据发送完毕之后, 向主动端发送`FIN`报文, 主动端收到此报文并应答之后, 进入`TIME_WAIT`状态
>
> 也就是说, 主动端向被动端 发送`ACK`应答报文之后, 才进入了`TIME_WAIT`
>
> 被动端是需要收到主动端的`ACK`应答报文才能正常关闭连接的, 所以主动端是需要保证 被动端确实收到了`ACK`应答报文的
>
> 如果, 被动端没有收到主动端的`ACK`报文, 那么被动端是会重传`FIN`报文的
>
> 因为, 被动端可能重传`FIN`报文, 所以 **主动端需要维持一段时间的`TIME_WAIT`状态, 保证可能重传的`FIN`报文不被漏掉**
>
> 这是`TIME_WAIT`状态存在的第一个作用
>
> ---
>
> 其次, 如果在主动端应答了`ACK`报文之后, 不维护`TIME_WAIT`状态 直接关闭连接, 被动端也收到了`ACK`报文正常的关闭了连接. 但是, 实际上网络中还有报文在有效传输
>
> 如果, 此时 恰好 双端使用了相同的四元组(源IP/目的IP:源Port/目的Port)建立了新的连接
>
> 那么 新的连接有没有可能会收到 旧的有效报文呢? 旧报文会不会影响此次的连接呢?
>
> 答案当然是有可能的. 虽然因为序号和确认序号等标识 被影响的概率很低
>
> 所以, 需要维护一段时间的`TIME_WAIT`状态, 保证旧报文传输完毕或失效, 这是第二个作用

> 关于第二个问题:
>
> 在简单分析"四次挥手"双端状态时, 提到过 `TIME_WAIT`的持续时间不能太长, 不能太短, `TCP`协议标准 推荐值为`2*MSL`
>
> **`MSL(Maximum Segment Lifetime)`, 表示 `TCP`报文在网络中的最大生存时间**. 不同系统 可能设置不同的`MSL`, 如果一个`TCP`报文在网络中传输的时间超过了系统的`MSL`, 那么此报文到达目的地时会被丢弃
>
> **`TCP`协议标准 推荐`TIME_WAIT`的持续时长为`2倍MSL`, 为什么呢?**
>
> 因为 如果`TIME_WAIT`持续`2*MSL`的时长, 那么基本可以保证此次连接 双方发送的报文 都已经传输完毕或已经失效
>
> 如果, 主动端在`TIME_WAIT`期间 再次收到了被动端的`FIN`报文, 主动端会重新发送`ACK`报文并进入新的`TIME_WAIT`
>
> 那么, 主动端发送`ACK`应答报文之后, 此报文会有两种结果:
>
> 1. 丢失, 即被动端一直没收到`ACK`报文
>
>     此时, 被动端会一直重传`FIN`, 直到达到重传的上限
>
>     否则, 双端的状态一般是不会变化的
>
>     > 你可能会想, 如果被动端一直在重传`FIN`, 但是每一个都没有被主动端收到
>     >
>     > 然后重传时间超出了`2*MSL`, 主动端都关闭连接了, 被动端还在重传`FIN`
>     >
>     > 如果出现了这种情况, 那么在被动端达到重传上限之前, 网络中会一直存在有效的`FIN`报文
>     >
>     > 这怎么解决?
>     >
>     > 只能说出现这种情况的概率, 非常非常低. 不过 在此种情况中, 由于被动端在达到重传上线之前一直没有关闭连接, 也就没有释放资源, 系统一直占用着四元组资源
>     >
>     > 所以, 也不会出现 双端使用相同四元组建立新连接的情况
>     >
>     > ---
>     >
>     > 当然, 还有最极限的一种情况: 被动端刚好达到重传上限, 重传了最后一个`FIN`报文, 刚好关闭连接释放资源, 双端就使用了相同的四元组建立了新的连接
>     >
>     > 此时, 网络中还传输有有效的`FIN`报文, 新连接就又可能被影响
>     >
>     > 但是, 好像还是无法解决, 只能说出现这种情况的概率 更更更更低了
>     >
>     > ---
>     >
>     > 这都是非常非常非常极端的情况, 基本不需要考虑
>
> 2. 被动端收到了`ACK`报文
>
>     那么, 以此报文可以被接收为前提, 最长的传输时长就是不超过`MSL`
>
>     并且, 被动端有可能在收到`ACK`的前一瞬 刚好重传了一份`FIN`报文, 那么 这一份`FIN`在网络中传输失效需要的时间就是`MSL`
>
>     **`ACK`最长的传输时间+`FIN`传输失效需要的时间<=`2*MSL`**
>
>     所以, `TCP`协议标准 推荐`TIME_WAIT`持续时长为`2*MSL`
>
> ---
>
> 那么, Linux系统中的`MSL`实现的是多少呢?
>
> 按照`TCP`标准的建议, `TIME_WAIT`持续`2*MSL`. 而 我们实测`TIME_WAIT`会持续约`60s`
>
> 那么, Linux的`MSL`就应该是`30`
>
> 但实际不是的. 查看`Linux`源码可以看到, `MSL=60`:
>
> ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401300028550.webp)
>
> 同样 可以看到`TIME_WAIT`的持续时间, 也可以看作默认`60s`:
>
> ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401300037389.webp)
>
> > Linux系统实现的`TIME_WAIT`的持续时间, 并不只是简单的`60s`, 但是一般可以看作是`60s`
>
> 并且, 可以在源码中看到有关`FIN_WAIT_2`状态的定义`TCP_FIN_TIMEOUT`, 实际就是`TCP_TIMEWAIT_LEN`
>
> 所以, 在Linux系统中查看`TCP_FIN_TIMEOUT`就是查看`TCP_TIMEWAIT_LEN`, 也可以看作是查看Linux系统的`MSL`:
>
> `cat /proc/sys/net/ipv4/tcp_fin_timeout`
>
> ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401300039718.webp)
>
> ---
>
> 查看源码我们发现, Linux针对`TIME_WAIT`状态持续时间的实现, 并没有按照`TCP`协议标准的建议走
>
> 而是将`TCP_TIMEWAIT_LEN`设置为了与`TCP_PAWS_MSL`相同的值`60`
>
> 因为Linux针对`TIME_WAIT`有其他方面的优化

---

###### 可能造成的问题 和 解决

`TIME_WAIT`持续太久, 也会无效占用系统资源, 除了占用系统资源之外, 可能会造成一些其他:

如果是服务端`TIME_WAIT`持续太久, 会出现这种情况:

![](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401301633910.webp)

由于服务端主动关闭连接, 维持在`TIME_WAIT`状态, 导致端口资源无法释放, 耽误服务重启

Linux系统`TIME_WAIT`维持时间在`60s`左右

服务器在实际运行中, 如果整个服务挂掉了, 服务器建立的每一个连接都会进入`TIME_WAIT`, 只要有一个连接没有正式关闭, 服务就无法使用相同的端口重启, 难道服务要等待`60s`再重启吗?

要解决这个问题, 除了直接从系统层面做优化之外. Linux还提供了一个系统调用`setsockopt()`

```cpp
#include <sys/socket.h>

int setsockopt(int sockfd, int level, int optname,
               const void *optval, socklen_t optlen);
/*
 * sockfd, 创建的套接字
 * level, 协议层 可以指定协议, 这里使用 SOL_SOCKET
 * optname, 选项名
 * optval, 要设置的值/内容, 需要根据选项的实际类型进行定义和填充, 是一个输入性参数
 * optlen, optval的长度/大小
 */
```

这个系统调用可以 对进程中的指定`socket`的行为 做出一些调整, 即 设置套接字的一些选项, 需要调用在创建套接字之后

有两个选项, 可以使相同的服务直接使用相同的端口/IP创建套接字, 即使之前的连接还未正式关闭

这两个选项看作布尔值, 可以直接以`0/1`设置

1. `SO_REUSEADDR`

    可以在服务进入`TIME_WAIT`之后, 即使 没有正式关闭连接, 让服务使用相同的`Port`和`IP`创建`socket`并`bind`. 不过前提是, 需要是同一个服务

    ```cpp
    // 创建套接字之后
    int opt = 1;
    setsockopt(_listenSock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
    ```

    ![在TIME_WAIT状态 |wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401301714483.webp)

    

2. `SO_REUSEPORT`

    允许不同服务在任何状态下, 使用相同的`Port`和`IP`创建`socket`并`bind`, 之前的服务的连接不用在`TIME_WAIT`状态

    ```cpp
    // 创建套接字之后
    int opt = 1;
    setsockopt(_listenSock, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt));
    ```

    ![|wide](https://dxyt-july-image.oss-cn-beijing.aliyuncs.com/202401301721903.webp)

